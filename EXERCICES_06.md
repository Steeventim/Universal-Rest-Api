# ðŸ§ª TP Niveau 6 - Base de donnÃ©es : Exercices Pratiques

## ðŸŽ¯ Vue d'ensemble des Exercices

**DurÃ©e totale :** 6-7 heures  
**Progression :** Bronze â†’ Silver â†’ Gold  
**Objectif :** MaÃ®triser l'intÃ©gration des bases de donnÃ©es dans les APIs REST

---

## ðŸ¥‰ **NIVEAU BRONZE** - Configuration de Base (2-3h)

### Exercice 1 : Setup MongoDB avec Mongoose (45min)

#### ðŸŽ¯ Objectif

Configurer MongoDB et crÃ©er vos premiers modÃ¨les avec Mongoose.

#### ðŸ“‹ Instructions

1. **Installation et configuration**

   ```bash
   # Installer les dÃ©pendances MongoDB
   npm install mongodb mongoose @types/mongoose

   # DÃ©marrer MongoDB avec Docker
   docker run -d --name mongo-tp -p 27017:27017 mongo:6.0
   ```

2. **CrÃ©er la configuration MongoDB**

   - ImplÃ©menter `src/database/config/mongodb.ts`
   - Pattern Singleton pour la connexion
   - Gestion des erreurs de connexion

3. **CrÃ©er le modÃ¨le Item pour MongoDB**

   ```typescript
   // SchÃ©ma avec validation complÃ¨te
   - name: string (requis, max 100 chars)
   - description: string (optionnel, max 500 chars)
   - price: number (requis, positif)
   - category: enum ['electronique', 'vetement', 'livre', 'autre']
   - tags: string[] (optionnel)
   - isActive: boolean (dÃ©faut: true)
   - timestamps automatiques
   ```

4. **CrÃ©er des index pour la performance**
   - Index de recherche textuelle sur name/description
   - Index composÃ© sur category/isActive
   - Index simple sur price

#### âœ… Tests de Validation

```bash
# Test de connexion
curl http://localhost:3000/api/health/mongodb

# Test CRUD basique
curl -X POST http://localhost:3000/api/items \
  -H "Content-Type: application/json" \
  -d '{"name":"Test MongoDB","price":99.99,"category":"electronique"}'

# VÃ©rifier dans MongoDB
mongosh
> use api_tp
> db.items.find()
```

#### ðŸŽ¯ CritÃ¨res de RÃ©ussite

- [ ] Connexion MongoDB stable
- [ ] ModÃ¨le Mongoose avec validation
- [ ] Index crÃ©Ã©s et fonctionnels
- [ ] CRUD basique opÃ©rationnel

---

### Exercice 2 : Setup PostgreSQL avec Prisma (45min)

#### ðŸŽ¯ Objectif

Configurer PostgreSQL et utiliser Prisma comme ORM moderne.

#### ðŸ“‹ Instructions

1. **Installation et initialisation**

   ```bash
   # Installer Prisma
   npm install prisma @prisma/client
   npm install --save-dev @types/pg

   # Initialiser Prisma
   npx prisma init

   # DÃ©marrer PostgreSQL
   docker run -d --name postgres-tp \
     -e POSTGRES_DB=api_tp \
     -e POSTGRES_USER=postgres \
     -e POSTGRES_PASSWORD=password \
     -p 5432:5432 postgres:15
   ```

2. **DÃ©finir le schÃ©ma Prisma**

   ```prisma
   // prisma/schema.prisma
   model Item {
     id          Int      @id @default(autoincrement())
     name        String   @db.VarChar(100)
     description String?  @db.VarChar(500)
     price       Decimal  @db.Decimal(10, 2)
     category    Category
     tags        String[]
     isActive    Boolean  @default(true)
     createdAt   DateTime @default(now())
     updatedAt   DateTime @updatedAt

     @@index([category, isActive])
     @@index([price])
     @@map("items")
   }
   ```

3. **GÃ©nÃ©rer et exÃ©cuter les migrations**

   ```bash
   npx prisma migrate dev --name init
   npx prisma generate
   ```

4. **CrÃ©er la configuration PostgreSQL**
   - Client Prisma avec logging
   - MÃ©thodes de connexion/dÃ©connexion
   - Gestion des erreurs

#### âœ… Tests de Validation

```bash
# Test de connexion
curl http://localhost:3000/api/health/postgresql

# Test avec Prisma Studio
npx prisma studio

# Test CRUD
curl -X POST http://localhost:3000/api/items \
  -H "Content-Type: application/json" \
  -d '{"name":"Test PostgreSQL","price":149.99,"category":"livre"}'
```

#### ðŸŽ¯ CritÃ¨res de RÃ©ussite

- [ ] PostgreSQL connectÃ© via Prisma
- [ ] SchÃ©ma de donnÃ©es migrÃ©
- [ ] Client Prisma configurÃ©
- [ ] Prisma Studio accessible

---

### Exercice 3 : Interface Repository Pattern (60min)

#### ðŸŽ¯ Objectif

ImplÃ©menter le pattern Repository pour abstraire l'accÃ¨s aux donnÃ©es.

#### ðŸ“‹ Instructions

1. **CrÃ©er l'interface IItemRepository**

   ```typescript
   interface IItemRepository {
     findAll(options?: FindAllOptions): Promise<IItem[]>;
     findById(id: string): Promise<IItem | null>;
     create(item: Omit<IItem, "id">): Promise<IItem>;
     update(id: string, item: Partial<IItem>): Promise<IItem | null>;
     delete(id: string): Promise<boolean>;
     findByCategory(category: string): Promise<IItem[]>;
     search(query: string): Promise<IItem[]>;
     count(filter?: any): Promise<number>;
   }
   ```

2. **ImplÃ©menter MongoItemRepository**

   - Toutes les mÃ©thodes avec Mongoose
   - Gestion des erreurs spÃ©cifiques MongoDB
   - Optimisations des requÃªtes

3. **ImplÃ©menter PostgresItemRepository**

   - Toutes les mÃ©thodes avec Prisma
   - Conversion des types Prisma vers interface
   - Gestion des erreurs PostgreSQL

4. **CrÃ©er un Factory Pattern**
   ```typescript
   class RepositoryFactory {
     static createItemRepository(): IItemRepository {
       const dbType = process.env.DB_TYPE || "mongodb";

       switch (dbType) {
         case "mongodb":
           return new MongoItemRepository();
         case "postgres":
           return new PostgresItemRepository();
         default:
           throw new Error(`Database type ${dbType} not supported`);
       }
     }
   }
   ```

#### âœ… Tests de Validation

```bash
# Test avec MongoDB
DB_TYPE=mongodb npm run test:repository

# Test avec PostgreSQL
DB_TYPE=postgres npm run test:repository

# Test du factory pattern
npm run test:factory
```

#### ðŸŽ¯ CritÃ¨res de RÃ©ussite

- [ ] Interface Repository complÃ¨te
- [ ] ImplÃ©mentations MongoDB et PostgreSQL
- [ ] Factory pattern fonctionnel
- [ ] Tests passants pour les deux bases

---

## ðŸ¥ˆ **NIVEAU SILVER** - IntÃ©gration AvancÃ©e (3-4h)

### Exercice 4 : Cache Layer avec Redis (90min)

#### ðŸŽ¯ Objectif

IntÃ©grer Redis pour amÃ©liorer les performances avec un systÃ¨me de cache intelligent.

#### ðŸ“‹ Instructions

1. **Setup Redis**

   ```bash
   # Installer Redis
   npm install redis ioredis @types/ioredis

   # DÃ©marrer Redis
   docker run -d --name redis-tp -p 6379:6379 redis:7-alpine
   ```

2. **CrÃ©er RedisClient avec Singleton**

   ```typescript
   // Configuration avec retry et monitoring
   - Connexion avec options avancÃ©es
   - Gestion des Ã©vÃ©nements (connect, error, ready)
   - Pool de connexions si nÃ©cessaire
   ```

3. **ImplÃ©menter CacheService**

   ```typescript
   // MÃ©thodes de cache
   - getItem(id): IItem | null
   - setItem(id, item, ttl): void
   - deleteItem(id): void
   - getItemsList(key): IItem[] | null
   - setItemsList(key, items, ttl): void
   - invalidateItem(id): void
   - invalidateListsCache(): void
   - getCacheStats(): CacheStats
   ```

4. **StratÃ©gies de cache**
   - Cache-aside pattern
   - TTL adaptatif selon le type de donnÃ©e
   - Invalidation en cascade
   - Compression pour gros objets

#### âœ… Tests de Validation

```bash
# Test de performance sans cache
time curl http://localhost:3000/api/items

# Test de performance avec cache
time curl http://localhost:3000/api/items # 2Ã¨me appel

# VÃ©rifier Redis
redis-cli
> KEYS *
> GET "item:1"

# Stats du cache
curl http://localhost:3000/api/cache/stats
```

#### ðŸŽ¯ CritÃ¨res de RÃ©ussite

- [ ] Redis connectÃ© et stable
- [ ] Cache service complet
- [ ] AmÃ©lioration mesurable des performances
- [ ] Invalidation du cache fonctionnelle

---

### Exercice 5 : Service IntÃ©grÃ© avec Cache (60min)

#### ðŸŽ¯ Objectif

Modifier le ItemService pour intÃ©grer transparentement le cache.

#### ðŸ“‹ Instructions

1. **Modifier ItemService**

   ```typescript
   // Pattern cache-aside dans chaque mÃ©thode
   getById(id):
     1. VÃ©rifier cache
     2. Si pas trouvÃ© â†’ base de donnÃ©es
     3. Mettre en cache le rÃ©sultat

   getAll(options):
     1. CrÃ©er clÃ© de cache basÃ©e sur options
     2. VÃ©rifier cache
     3. Si pas trouvÃ© â†’ base de donnÃ©es + cache

   create(item):
     1. CrÃ©er en base
     2. Mettre en cache
     3. Invalider les listes

   update(id, data):
     1. Modifier en base
     2. Mettre Ã  jour le cache
     3. Invalider les listes

   delete(id):
     1. Supprimer de la base
     2. Invalider le cache
   ```

2. **Gestion intelligente du cache**

   - TTL diffÃ©renciÃ© par type d'opÃ©ration
   - Cache conditionnel selon la taille des donnÃ©es
   - Monitoring des hit/miss ratios

3. **Fallback et rÃ©silience**
   - Fonctionnement si Redis est down
   - Circuit breaker pattern
   - Logs de performance

#### âœ… Tests de Validation

```bash
# Test de performance complÃ¨te
npm run benchmark:api

# Test de rÃ©silience (arrÃªter Redis)
docker stop redis-tp
curl http://localhost:3000/api/items # Doit fonctionner

# RedÃ©marrer Redis
docker start redis-tp
curl http://localhost:3000/api/items # Cache doit se reconstruire
```

#### ðŸŽ¯ CritÃ¨res de RÃ©ussite

- [ ] Service avec cache transparent
- [ ] Performance amÃ©liorÃ©e significativement
- [ ] RÃ©silience si cache indisponible
- [ ] Monitoring des performances

---

### Exercice 6 : Migrations et Seeders (90min)

#### ðŸŽ¯ Objectif

CrÃ©er un systÃ¨me complet de migrations et de donnÃ©es de test.

#### ðŸ“‹ Instructions

1. **Scripts de migration PostgreSQL**

   ```sql
   -- migrations/001_init_schema.sql
   CREATE TYPE category_enum AS ENUM (...);
   CREATE TABLE items (...);
   CREATE INDEX ...;

   -- migrations/002_add_full_text_search.sql
   CREATE INDEX idx_items_search ON items
   USING gin(to_tsvector('french', name || ' ' || description));

   -- migrations/003_add_audit_fields.sql
   ALTER TABLE items ADD COLUMN created_by INTEGER;
   ALTER TABLE items ADD COLUMN updated_by INTEGER;
   ```

2. **Seeders avec donnÃ©es rÃ©alistes**

   ```typescript
   // CrÃ©er 1000+ items variÃ©s
   - DiffÃ©rentes catÃ©gories Ã©quilibrÃ©es
   - Prix rÃ©alistes par catÃ©gorie
   - Tags pertinents
   - Descriptions dÃ©taillÃ©es
   ```

3. **Scripts de gestion**

   ```typescript
   // scripts/migrate.ts
   - ExÃ©cution sÃ©quentielle des migrations
   - Tracking des versions appliquÃ©es
   - Rollback si erreur

   // scripts/seed.ts
   - Nettoyage optionnel des donnÃ©es existantes
   - Insertion par batch pour performance
   - Progression et statistiques
   ```

4. **Migration MongoDB Ã©quivalente**
   ```typescript
   // SystÃ¨me de versions pour MongoDB
   - Collection migrations pour tracking
   - Scripts d'Ã©volution du schÃ©ma
   - Validation des donnÃ©es existantes
   ```

#### âœ… Tests de Validation

```bash
# Migration PostgreSQL
npm run db:migrate

# Seeding
npm run db:seed

# VÃ©rification des donnÃ©es
curl http://localhost:3000/api/items?limit=100

# Test de performance avec gros dataset
time curl http://localhost:3000/api/items/search?q=smartphone

# Rollback et re-migration
npm run db:rollback
npm run db:migrate
```

#### ðŸŽ¯ CritÃ¨res de RÃ©ussite

- [ ] SystÃ¨me de migration complet
- [ ] Seeders avec donnÃ©es variÃ©es (1000+ items)
- [ ] Scripts de gestion automatisÃ©s
- [ ] Performance stable avec gros dataset

---

## ðŸ¥‡ **NIVEAU GOLD** - Production Ready (2-3h)

### Exercice 7 : Optimisations de Performance (90min)

#### ðŸŽ¯ Objectif

Optimiser les performances pour un environnement de production.

#### ðŸ“‹ Instructions

1. **Analyse des performances actuelles**

   ```typescript
   // Middleware de monitoring des requÃªtes
   - Temps d'exÃ©cution par endpoint
   - Analyse des requÃªtes lentes (>1s)
   - Statistiques de cache hit/miss
   - Monitoring de la mÃ©moire
   ```

2. **Optimisations MongoDB**

   ```typescript
   // Index composÃ©s optimisÃ©s
   { category: 1, price: 1, isActive: 1 }
   { tags: 1, isActive: 1 }
   { name: "text", description: "text" }

   // Aggregation pipeline pour requÃªtes complexes
   - Pagination efficace avec $skip/$limit
   - Recherche avec scoring
   - Statistiques par catÃ©gorie
   ```

3. **Optimisations PostgreSQL**

   ```sql
   -- Index partiels pour requÃªtes frÃ©quentes
   CREATE INDEX idx_active_items ON items(category, price)
   WHERE is_active = true;

   -- Index GIN pour recherche full-text
   CREATE INDEX idx_search_items ON items
   USING gin(to_tsvector('french', name || ' ' || description));

   -- Statistiques et VACUUM automatique
   ```

4. **Connection Pooling et Optimisations**

   ```typescript
   // MongoDB avec pool de connexions
   mongoose.connect(uri, {
     maxPoolSize: 10,
     minPoolSize: 2,
     maxIdleTimeMS: 30000,
     serverSelectionTimeoutMS: 5000,
   });

   // PostgreSQL avec Prisma pool
   new PrismaClient({
     datasources: {
       db: {
         url: DATABASE_URL + "?connection_limit=20&pool_timeout=20",
       },
     },
   });
   ```

#### âœ… Tests de Validation

```bash
# Load testing
npm install -g artillery
artillery quick --count 100 --num 10 http://localhost:3000/api/items

# Analyse des index
# MongoDB
db.items.getIndexes()
db.items.explain("executionStats").find({category: "electronique"})

# PostgreSQL
EXPLAIN ANALYZE SELECT * FROM items WHERE category = 'electronique';

# Monitoring continu
npm run performance:monitor
```

#### ðŸŽ¯ CritÃ¨res de RÃ©ussite

- [ ] RÃ©ponse <200ms pour 95% des requÃªtes
- [ ] Index optimisÃ©s et utilisÃ©s
- [ ] Connection pooling configurÃ©
- [ ] Load testing rÃ©ussi (100 users concurrent)

---

### Exercice 8 : Backup et Recovery (60min)

#### ðŸŽ¯ Objectif

ImplÃ©menter une stratÃ©gie complÃ¨te de sauvegarde et rÃ©cupÃ©ration.

#### ðŸ“‹ Instructions

1. **Scripts de backup automatisÃ©s**

   ```bash
   #!/bin/bash
   # scripts/backup-mongodb.sh
   mongodump --host localhost:27017 --db api_tp \
     --out /backups/mongodb/$(date +%Y%m%d_%H%M%S)

   # scripts/backup-postgresql.sh
   pg_dump -h localhost -U postgres api_tp \
     > /backups/postgresql/api_tp_$(date +%Y%m%d_%H%M%S).sql
   ```

2. **StratÃ©gie de rÃ©tention**

   ```typescript
   // Politique de backup
   - Backup complet quotidien
   - Backup incrÃ©mental toutes les 6h
   - RÃ©tention : 7 jours quotidiens, 4 semaines hebdomadaires
   - Backup avant chaque migration
   ```

3. **Scripts de restauration**

   ```bash
   # Test de restauration complÃ¨te
   # CrÃ©er une base de test
   # Restaurer le backup
   # Valider l'intÃ©gritÃ© des donnÃ©es
   ```

4. **Monitoring et alertes**
   ```typescript
   // VÃ©rification de l'intÃ©gritÃ©
   - Checksum des backups
   - Test de restauration automatique
   - Alertes si backup Ã©choue
   - MÃ©triques de taille et durÃ©e
   ```

#### âœ… Tests de Validation

```bash
# Test backup complet
npm run backup:all

# Test de restauration
npm run restore:test

# Simulation de disaster recovery
docker stop postgres-tp mongo-tp redis-tp
npm run disaster:recovery

# Validation de l'intÃ©gritÃ©
npm run backup:verify
```

#### ðŸŽ¯ CritÃ¨res de RÃ©ussite

- [ ] Backup automatisÃ© fonctionnel
- [ ] Restauration testÃ©e et validÃ©e
- [ ] StratÃ©gie de rÃ©tention implÃ©mentÃ©e
- [ ] Tests de disaster recovery rÃ©ussis

---

### Exercice 9 : Monitoring et Alertes Production (90min)

#### ðŸŽ¯ Objectif

Mettre en place un monitoring complet pour la production.

#### ðŸ“‹ Instructions

1. **MÃ©triques de base de donnÃ©es**

   ```typescript
   // Dashboard de mÃ©triques
   - Connexions actives
   - Temps de rÃ©ponse des requÃªtes
   - Utilisation de la mÃ©moire
   - Taille des bases de donnÃ©es
   - Hit ratio du cache
   ```

2. **Health checks avancÃ©s**

   ```typescript
   // Endpoint /health dÃ©taillÃ©
   {
     "status": "healthy",
     "databases": {
       "mongodb": { "status": "connected", "latency": "5ms" },
       "postgresql": { "status": "connected", "latency": "3ms" },
       "redis": { "status": "connected", "latency": "1ms" }
     },
     "performance": {
       "avgResponseTime": "150ms",
       "slowQueries": 2,
       "cacheHitRate": "95%"
     }
   }
   ```

3. **Alertes configurables**

   ```typescript
   // Seuils d'alerte
   - Latence > 500ms â†’ Warning
   - Latence > 1000ms â†’ Critical
   - Cache hit rate < 80% â†’ Warning
   - Connexions > 80% pool â†’ Warning
   - Disk space < 20% â†’ Critical
   ```

4. **Logs structurÃ©s**
   ```typescript
   // Logging avec Winston
   - Logs de performance par requÃªte
   - Logs d'erreur avec context
   - Logs de sÃ©curitÃ© (tentatives d'accÃ¨s)
   - Rotation automatique des logs
   ```

#### âœ… Tests de Validation

```bash
# Test du monitoring
curl http://localhost:3000/health

# Simulation de charge pour dÃ©clencher alertes
npm run stress:test

# VÃ©rification des logs
tail -f logs/api.log | grep ERROR

# Dashboard de mÃ©triques
curl http://localhost:3000/metrics
```

#### ðŸŽ¯ CritÃ¨res de RÃ©ussite

- [ ] Monitoring complet fonctionnel
- [ ] Health checks dÃ©taillÃ©s
- [ ] Alertes configurÃ©es et testÃ©es
- [ ] Logs structurÃ©s et rotatifs

---

## ðŸ”¥ **BONUS - DÃ©fis AvancÃ©s**

### DÃ©fi 1 : Multi-tenant avec bases sÃ©parÃ©es

```typescript
// Gestion de plusieurs clients avec bases dÃ©diÃ©es
- Routing automatique selon le tenant
- Migrations par tenant
- Backup isolÃ© par client
```

### DÃ©fi 2 : RÃ©plication Master/Slave

```typescript
// Configuration haute disponibilitÃ©
- Master pour Ã©criture, Slaves pour lecture
- Failover automatique
- Consistance Ã©ventuelle
```

### DÃ©fi 3 : Sharding horizontal

```typescript
// Partitionnement des donnÃ©es
- StratÃ©gie de partitionnement par catÃ©gorie
- Router de requÃªtes automatique
- Gestion des requÃªtes cross-shard
```

---

## ðŸ“Š Grille d'Ã‰valuation Globale

### Bronze (Fondamentaux) - 60 points

- Configuration bases de donnÃ©es : 20 pts
- Repository pattern : 20 pts
- Tests d'intÃ©gration : 20 pts

### Silver (IntermÃ©diaire) - 80 points

- Cache Redis intÃ©grÃ© : 30 pts
- Migrations/Seeders : 25 pts
- Performance optimisÃ©e : 25 pts

### Gold (Production) - 100 points

- Monitoring complet : 35 pts
- Backup/Recovery : 35 pts
- Optimisations avancÃ©es : 30 pts

**Score total possible : 240 points**

**Seuils de validation :**

- Bronze : 45+ points (75%)
- Silver : 60+ points (75%)
- Gold : 75+ points (75%)

---

ðŸŽ¯ **Objectif Final :** MaÃ®triser complÃ¨tement l'intÃ©gration des bases de donnÃ©es dans une API REST de niveau production, avec cache, monitoring et rÃ©silience.

âž¡ï¸ **Prochaine Ã©tape :** [TP Niveau 7 - API AvancÃ©e](./EXERCICES_07.md)
